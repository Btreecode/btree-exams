questions:
  - question: >-
      A programmer is designing an algorithm used to assess loan applications.  
      Which of the following would help reduce bias in the algorithm?

    correct_options:
      - Have people with diverse experiences review the algorithm and test data
    wrong_options:
      - Use only historical loan approval data to train the system
      - Apply a single fixed rule for all applicants
      - Minimize human involvement to avoid emotion
      - Use the fastest machine learning model available
    explanation: >-
      - **Correct:** Collaboration and diverse testing uncover bias in logic and data.
      - **Incorrect:** Relying on past data or eliminating human review may reinforce existing bias.

  - question: >-
      What is the main benefit of using **citizen science** to support butterfly population research?

      Select **two** correct answers.
    correct_options:
      - Citizens can gather large amounts of data across wide geographic areas
      - Social media can recruit participants from diverse locations
    wrong_options:
      - The public is better at identifying insects than experts
      - Volunteers can make conclusions without expert analysis
      - Scientific data is less important than anecdotal reports
    explanation: >-
      - **Correct:** Citizen science expands scale and reach.
      - **Incorrect:** Public contributions support, but don’t replace, expert insight.

  - question: >-
      A credit card company sends you an email with its logo, asking you to call the number on the back of your card to confirm a charge.  
      Which of the following makes this example **least likely** to be phishing?

    correct_options:
      - It asks you to call a trusted phone number you already have
    wrong_options:
      - It uses a company logo
      - It mentions your credit card
      - It uses strong emotional language
      - It says “URGENT” in the subject line
    explanation: >-
      - **Correct:** Encouraging use of a known, official contact method avoids redirection to fake links.
      - **Incorrect:** Logos and familiar info can be faked.

  - question: >-
      In 2013, hackers used a malicious link to infect a vendor’s system and gain access to millions of customer credit cards through Target’s payment processing.

      What type of attack was this?

    correct_options:
      - Phishing
    wrong_options:
      - SQL injection
      - Brute force
      - Keylogging
      - Packet interception
    explanation: >-
      - **Correct:** Social engineering and email bait were used to install malware.
      - **Incorrect:** The attack wasn’t based on direct data entry or login guessing.

  - question: >-
      A company trains an algorithm to review resumes but later finds that it ranks male applicants higher due to biased training data.

      What is the **most likely cause** of this issue?

    correct_options:
      - The training data reflected historical hiring bias
    wrong_options:
      - The algorithm was not tested on enough resumes
      - The algorithm used too many features
      - Resume order affected ranking
      - The output was not encrypted
    explanation: >-
      - **Correct:** Bias in historical hiring patterns gets baked into training sets.
      - **Incorrect:** Volume, encryption, or features don’t directly explain bias.

  - question: >-
      A computer has two identical processors. Processes 4 and 5 must run sequentially.  
      Processes 1–3 can run in parallel.

      | Process | Time (s) |
      |---------|----------|
      | One     | 3        |
      | Two     | 2        |
      | Three   | 5        |
      | Four    | 4        |
      | Five    | 4        |

      What is the **minimum time** to complete all processes?

    correct_options:
      - 13 seconds
    wrong_options:
      - 9 seconds
      - 18 seconds
      - 7 seconds
      - 11 seconds
    explanation: >-
      - **Correct:** Max(5,3+2) = 5 seconds for P1–3 in parallel; then 4+4 = 8 → total = 13s.
      - **Incorrect:** Others miscalculate parallel runtime or overlook dependency.

  - question: >-
      Which of the following are NOT advantages of simulations?

      Select **two** correct answers.
    correct_options:
      - They are more expensive than real-world experiments
      - They are always more accurate than actual experiments
    wrong_options:
      - They allow rapid testing of different conditions
      - They’re safer for testing dangerous situations
      - They reduce physical resources used
      - They can be adjusted more easily
    explanation: >-
      - **Correct:** Simulations reduce cost and offer control, but aren’t always more accurate.
      - **Incorrect:** Most benefits stem from flexibility and accessibility.

  - question: >-
      Which of the following would NOT be considered a **reasonable number of steps** for an algorithm?

    correct_options:
      - 3ⁿ
    wrong_options:
      - n
      - 4n + 8n²
      - 100n⁴
      - log₂(n)
    explanation: >-
      - **Correct:** 3ⁿ grows exponentially and becomes unreasonable quickly.
      - **Incorrect:** Polynomial and logarithmic growth are reasonable.

  - question: >-
      Which of the following are **benefits of easy access to information**?

      Select **two** correct answers.
    correct_options:
      - Researchers can access data to validate or refine findings
      - Students can better understand complex topics
    wrong_options:
      - All publicly available data is guaranteed to be accurate
      - Easy access ensures privacy is preserved
      - It guarantees unbiased information
    explanation: >-
      - **Correct:** Access helps support education and research.
      - **Incorrect:** Access ≠ accuracy, privacy, or objectivity.

  - question: >-
      A health app gives fitness advice. The app’s recommendations change depending on age, gender, and prior input history.  
      Over time, users are funneled toward only certain options.

      What **ethical concern** might arise?

    correct_options:
      - Algorithmic filtering may reduce diversity of choices
    wrong_options:
      - The app is too efficient
      - The app is using dynamic memory allocation
      - Health advice must never change
      - The app loads slowly on older devices
    explanation: >-
      - **Correct:** Algorithms can unintentionally limit exposure to alternative paths (filter bubble).
      - **Incorrect:** Speed and memory aren't ethical concerns in this context.
  - question: >-
      A student copies a photo from a website and uses it in a published blog post without giving credit.

      What issue does this raise?

    correct_options:
      - Copyright infringement
    wrong_options:
      - Data compression
      - Open-source violation
      - Phishing
      - Malware
      - Public domain use
    explanation: >-
      - **Correct:** Reusing copyrighted content without permission or attribution is a legal issue.
      - **Incorrect:** This isn't about security or software access.

  - question: >-
      Which of the following are benefits of **open-source software**?

      Select **three** correct answers.
    correct_options:
      - Developers can modify and improve the code
      - It is freely available for anyone to use
      - It promotes community-driven innovation
    wrong_options:
      - It ensures the software is always secure
      - It can only be used for nonprofit projects
      - It prevents all forms of hacking
    explanation: >-
      - **Correct:** Open-source promotes accessibility, customization, and community contributions.
      - **Incorrect:** Open-source does not guarantee security or restrict use.

  - question: >-
      A rural community lacks stable broadband internet, making it difficult for students to complete assignments or access lessons during remote learning.

      What issue does this illustrate?

    correct_options:
      - The digital divide
    wrong_options:
      - Hardware compatibility
      - File format errors
      - Network redundancy
      - IPv6 transition issues
    explanation: >-
      - **Correct:** Digital divide describes unequal access to technology and the internet.
      - **Incorrect:** Technical specs and formats aren’t the root of this access gap.

  - question: >-
      Which of the following are **consequences of unequal access to computing resources**?

      Select **two** correct answers.
    correct_options:
      - Some students have fewer opportunities to practice computer science skills
      - Communities with limited access may struggle to participate in digital economies
    wrong_options:
      - Computers will overheat more often in rural areas
      - Those with access always become computer experts
      - Devices with smaller screens are more biased
      - Broadband is guaranteed by law
    explanation: >-
      - **Correct:** Inequity in access results in skill gaps and economic disadvantages.
      - **Incorrect:** Technical assumptions or overgeneralizations are misleading.

  - question: >-
      Which of the following licenses allows others to freely use, share, and modify a work as long as credit is given?

    correct_options:
      - Creative Commons (Attribution)
    wrong_options:
      - Copyright (All Rights Reserved)
      - Software EULA
      - Private repository license
      - Trade secret protections
      - None of the above
    explanation: >-
      - **Correct:** Creative Commons licenses encourage sharing with proper attribution.
      - **Incorrect:** Other licenses restrict use or are not freely shareable.

  - question: >-
      A school uses **open-source platforms** for student projects.  
      Which of the following are potential advantages?

      Select **two** correct answers.
    correct_options:
      - Students can explore how the software works behind the scenes
      - The school avoids costly software licenses
    wrong_options:
      - Students are less likely to encounter bugs
      - Software never needs updating
      - Only computer science students can use it
      - Open-source means the data is public
    explanation: >-
      - **Correct:** Open-source software supports transparency and cost savings.
      - **Incorrect:** Bugs and updates still apply; access isn’t restricted to experts.

  - question: >-
      A popular online resource offers free, editable learning materials and allows users to improve or remix them.

      What term best describes this practice?

    correct_options:
      - Open access
    wrong_options:
      - Malware sharing
      - Encryption
      - Exclusive copyright
      - Brute force learning
      - Blacklisting
    explanation: >-
      - **Correct:** Open access allows anyone to use and improve materials freely.
      - **Incorrect:** Other terms relate to security or limitations.

  - question: >-
      Which of the following statements are true about **open data**?

      Select **two** correct answers.
    correct_options:
      - It allows researchers to validate findings by examining raw datasets
      - It promotes transparency in government or scientific studies
    wrong_options:
      - It guarantees that data is correct
      - It prevents the spread of misinformation
      - It limits collaboration due to data volume
      - It can only be accessed by professionals
    explanation: >-
      - **Correct:** Open data supports transparency and reproducibility.
      - **Incorrect:** Open data may contain errors or require interpretation.
  - question: >-
      A police department uses a predictive policing algorithm to identify areas with a high likelihood of crime. Over time, the same neighborhoods are repeatedly flagged and patrolled, even though the number of reported incidents there is declining.

      What is the **most likely ethical concern**?

    correct_options:
      - The algorithm reinforces bias present in its training data
    wrong_options:
      - The algorithm is not fast enough to process live data
      - The algorithm was open-source, which made it less secure
      - The police failed to use location-based services
      - The algorithm increases internet traffic in those areas
    explanation: >-
      - **Correct:** Predictive systems can create feedback loops if based on biased data.
      - **Incorrect:** Performance and security are not the issue here.

  - question: >-
      A company uses AI to review job applications. Applicants with non-traditional education paths or gaps in employment are often ranked lower, even if qualified.

      What are the main **social impacts** of this algorithm?

      Select **two** correct answers.
    correct_options:
      - It may unintentionally exclude qualified candidates
      - It may reduce workforce diversity
    wrong_options:
      - It increases algorithm efficiency
      - It helps hire only candidates from top universities
      - It guarantees better hiring decisions
      - It avoids human bias entirely
    explanation: >-
      - **Correct:** Automated filters can overlook qualified individuals and reinforce existing biases.
      - **Incorrect:** AI does not eliminate bias — it can amplify it if unchecked.

  - question: >-
      A school district uses a proprietary algorithm to place students in classes. Some students are consistently placed in remedial sections without explanation. The district refuses to share how placements are made.

      What ethical issue does this raise?

    correct_options:
      - Lack of transparency and accountability in algorithmic decision-making
    wrong_options:
      - Students are spending too much time online
      - The algorithm is not open-source
      - The algorithm runs too slowly
      - The software is copyrighted
    explanation: >-
      - **Correct:** Decisions that impact students should be explainable and reviewable.
      - **Incorrect:** Speed, source code, or copyright are unrelated.

  - question: >-
      An online platform shows different product prices to users based on location and device. Users in wealthier neighborhoods see higher prices than others.

      What is the **primary ethical concern**?

    correct_options:
      - Dynamic pricing may lead to unfair discrimination
    wrong_options:
      - The site is violating data encryption policies
      - The product selection is too broad
      - The algorithm is not mobile-optimized
      - Too many users are visiting the site at once
    explanation: >-
      - **Correct:** Pricing based on demographic profiling can be ethically problematic.
      - **Incorrect:** The issue is fairness, not performance or functionality.

  - question: >-
      A content platform shows users only stories that match their prior reading history, eventually filtering out differing viewpoints.

      What **negative consequence** could this cause?

    correct_options:
      - Users may become trapped in an echo chamber
    wrong_options:
      - The platform loses ad revenue
      - Users get access to fewer articles overall
      - The app requires higher bandwidth
      - The platform becomes less secure
    explanation: >-
      - **Correct:** Algorithmic filtering can reduce exposure to diverse ideas.
      - **Incorrect:** Technical or financial issues are not the concern here.

  - question: >-
      A logistics company replaces many warehouse workers with automated robots.  
      What are potential **societal consequences** of this decision?

      Select **two** correct answers.
    correct_options:
      - Job displacement for workers without advanced technical training
      - Increased productivity at the cost of reduced employment opportunities
    wrong_options:
      - Robots become sentient and take over the company
      - The company becomes open-source
      - Robots require healthcare benefits
      - Job postings increase immediately
    explanation: >-
      - **Correct:** Automation improves efficiency but may increase inequality and unemployment.
      - **Incorrect:** Sci-fi tropes or unrelated details aren't realistic impacts.

  - question: >-
      A startup uses facial recognition to unlock phones. However, users with darker skin tones report higher failure rates.

      What is the **likely cause**, and what should be done?

      Select **two** correct answers.
    correct_options:
      - The training data lacked sufficient diversity
      - The system should be audited for demographic bias
    wrong_options:
      - The cameras need better resolution
      - The software must run on faster processors
      - The phones should block darker backgrounds
      - The user must reset the system after each use
    explanation: >-
      - **Correct:** Biased training data creates discriminatory systems; review and retraining are essential.
      - **Incorrect:** Hardware or usage factors are not the root of the issue.
